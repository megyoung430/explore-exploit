import numpy as np
import matplotlib.pyplot as plt
from bandit_task_simulation import QLearningInferenceMouse, CorrelatedBanditTask
from analysis_fxns import GroupTrialsbyState, GetSwitchProbabilities
from plotting_fxns import PlotSummaryFigure, PlotOptoChoices, PlotSummaryPFigure, PlotSummaryQStatesFigure, PlotSummaryQActionsFigure

opto = True
num_perturbations = 1000
min_non_opto_trials = 900
snippet = 250
after_opto_action = []

if opto:

    for i in range(num_perturbations):
        # Define the parameters and structure of the task
        num_trials = 1000
        arms_across_states = [[0.5,0.9,0.1],[0.5,0.1,0.9]]
        num_arms = len(arms_across_states[0])
        drift_rates = np.zeros(num_arms)

        num_states = len(arms_across_states)
        state_switch_probability = 0.02
        state_change_probabilities = np.full((num_states,num_states),state_switch_probability)
        np.fill_diagonal(state_change_probabilities, 1-state_switch_probability)

        # Define the parameters for the mouse
        learning_rate = 0.05
        initial_state_prior = np.full((num_states),0.5)
        alpha = 0.25
        beta = 2

        # Define the parameters of the optogenetic stimulation
        delta_beta = 1
        delta_alpha = 2.25
        opto_change = "decrease stickiness"
        
        bandit_task = CorrelatedBanditTask(arms_across_states, state_change_probabilities, delta_beta, delta_alpha)
        mouse = QLearningInferenceMouse(num_arms, num_states, initial_state_prior, learning_rate, beta, alpha, opto_change)
        actions, rewards, switches, state_changes, posterior, q_states, q_actions, high_arm_opto_trial = bandit_task.simulate_optogenetics(mouse, num_trials, min_non_opto_trials)
        # If the agent chose the high arm, record that as a 2
        if actions[-1] == high_arm_opto_trial:
            after_opto_action.append(2)
        # If the agent chose the uncorrelated arm, record that as a 0
        elif actions[-1] == 0:
            after_opto_action.append(0)
        # If the agent chose the low arm, record that as a 1
        else:
            after_opto_action.append(1)
        
    PlotOptoChoices(after_opto_action, opto_change, delta_beta, delta_alpha)

else:
    
    # Define the parameters and structure of the task
    num_trials = 1000
    arms_across_states = [[0.5,0.9,0.1],[0.5,0.1,0.9]]
    num_arms = len(arms_across_states[0])
    drift_rates = np.zeros(num_arms)

    num_states = len(arms_across_states)
    state_switch_probability = 0.02
    state_change_probabilities = np.full((num_states,num_states),state_switch_probability)
    np.fill_diagonal(state_change_probabilities, 1-state_switch_probability)

    # Define the parameters for the mouse
    learning_rate = 0.05
    initial_state_prior = np.full((num_states),0.5)
    alpha = 0.25
    beta = 2

    # Define the parameters of the optogenetic stimulation
    delta_beta = 1
    delta_alpha = 0
    opto_change = "flip"

    bandit_task = CorrelatedBanditTask(arms_across_states, state_change_probabilities, delta_beta, delta_alpha)
    mouse = QLearningInferenceMouse(num_arms, num_states, initial_state_prior, learning_rate, beta, alpha, opto_change)
    actions, rewards, switches, state_changes, posterior, q_states, q_actions = bandit_task.simulate(mouse, num_trials)
    
    trial_groups = GroupTrialsbyState(bandit_task, state_changes, num_trials)
    PlotSummaryFigure(trial_groups, num_trials, snippet, actions, rewards, posterior, q_states, q_actions)
    # PlotSummaryPFigure(trial_groups, num_trials, snippet, actions, rewards, posterior)
    # PlotSummaryQStatesFigure(trial_groups, num_trials, snippet, actions, rewards, q_states)
    # PlotSummaryQActionsFigure(trial_groups, num_trials, snippet, actions, rewards, q_actions)