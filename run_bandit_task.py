import numpy as np
from bandit_task_simulation import QLearningMouse, CorrelatedBanditTask
from analysis_fxns import GetSwitchProbabilities

# Define the parameters and structure of the task
arms_across_states = [[0.5,0.9,0.1],[0.5,0.1,0.9]]
num_arms = len(arms_across_states[0])
drift_rates = np.zeros(num_arms)

num_states = len(arms_across_states)
state_switch_probability = 0.05
state_change_probabilities = np.full((num_states,num_states),state_switch_probability)
np.fill_diagonal(state_change_probabilities, 1-state_switch_probability)

# Define the parameters of the optogenetic stimulation
opto_probability = 0
opto_trial_threshold = 1000
delta_beta = 10
delta_alpha = 0.5

# Define the parameters for the mouse
learning_rate = 0.1
alpha = 0.3
beta = 3
opto_change = "increase exploration"

bandit_task = CorrelatedBanditTask(arms_across_states, state_change_probabilities, opto_probability, opto_trial_threshold, delta_beta, delta_alpha)
mouse = QLearningMouse(num_arms, learning_rate, beta, alpha, opto_change)
actions, rewards, switches, state_changes, opto_trials = bandit_task.simulate(mouse, 100000)