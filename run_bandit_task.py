import numpy as np
import matplotlib.pyplot as plt
from bandit_task_simulation import QLearningInferenceMouse, CorrelatedBanditTask
from analysis_fxns import GroupTrialsbyState, GetSwitchProbabilities
from plotting_fxns import PlotSummaryFigure, PlotOptoChoices, PlotSummaryPFigure, PlotSummaryQStatesFigure, PlotSummaryQActionsFigure

num_perturbations = 1000
after_opto_action = []

for i in range(num_perturbations):

    # Define the parameters and structure of the task
    num_trials = 1000
    snippet = 250
    arms_across_states = [[0.5,0.9,0.1],[0.5,0.1,0.9]]
    num_arms = len(arms_across_states[0])
    drift_rates = np.zeros(num_arms)

    num_states = len(arms_across_states)
    state_switch_probability = 0.05
    state_change_probabilities = np.full((num_states,num_states),state_switch_probability)
    np.fill_diagonal(state_change_probabilities, 1-state_switch_probability)

    # Define the parameters of the optogenetic stimulation
    opto_probability = 0
    opto_trial_threshold = 1000
    delta_beta = 0.1
    delta_alpha = 0.05

    # Define the parameters for the mouse
    learning_rate = 0.1
    initial_state_prior = np.full((num_states),0.5)
    alpha = 0.1
    beta = 2
    opto_change = "decrease stickiness"

    bandit_task = CorrelatedBanditTask(arms_across_states, state_change_probabilities, opto_probability, opto_trial_threshold, delta_beta, delta_alpha)
    mouse = QLearningInferenceMouse(num_arms, num_states, initial_state_prior, learning_rate, beta, alpha, opto_change)
    actions, rewards, switches, state_changes, posterior, q_states, q_actions = bandit_task.simulate(mouse, num_trials)
    after_opto_action.append(actions[-1])

# trial_groups = GroupTrialsbyState(bandit_task, state_changes, num_trials)
# PlotSummaryFigure(trial_groups, num_trials, snippet, actions, rewards, posterior, q_states, q_actions)
# PlotSummaryPFigure(trial_groups, num_trials, snippet, actions, rewards, posterior)
# PlotSummaryQStatesFigure(trial_groups, num_trials, snippet, actions, rewards, q_states)
# PlotSummaryQActionsFigure(trial_groups, num_trials, snippet, actions, rewards, q_actions)
PlotOptoChoices(after_opto_action, opto_change, delta_beta, delta_alpha)